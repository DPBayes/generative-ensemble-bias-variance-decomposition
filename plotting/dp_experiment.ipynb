{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from einops import rearrange, pack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../results/dp-experiment/\"\n",
    "fig_dir = \"../figures/dp-experiment/\"\n",
    "dataset = \"adult-reduced\"\n",
    "dataset_name = \"Adult\"\n",
    "metric_names = {\n",
    "    \"brier\": \"Brier Score\",\n",
    "    \"log_loss\": \"Cross Entropy\",\n",
    "    # \"accuracy\": \"Accuracy\",\n",
    "    # \"auc\": \"AUC\",\n",
    "    \"accuracy_comp\": \"1 - Accuracy\",\n",
    "    \"auc_comp\": \"1 - AUC\",\n",
    "}\n",
    "metrics = metric_names.keys()\n",
    "model_names = {\n",
    "    \"Logistic Regression\": \"LogR\",\n",
    "    \"1-NN\": \"1-NN\",\n",
    "    \"5-NN\": \"5-NN\",\n",
    "    \"Decision Tree\": \"DT\",\n",
    "    \"Random Forest\": \"RF\",\n",
    "    \"Gradient Boosting\": \"GB\",\n",
    "    \"MLP\": \"MLP\",\n",
    "    \"SVM\": \"SVM\",\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"{}{}/results.csv\".format(result_dir, dataset), index_col=False)\n",
    "df[\"model_short\"] = df.model.apply(lambda m: model_names[m])\n",
    "real_data_df = pd.read_csv(\"{}{}/real-data-results.csv\".format(result_dir, dataset), index_col=False)\n",
    "    \n",
    "df.primal = df.primal.apply(lambda m: \"Prob. Avg.\" if m== \"Primal\" else \"Log Prob. Avg.\")\n",
    "df[\"method_primal\"] = df.apply(lambda row: \"{} - {}\".format(row[\"method\"], row[\"primal\"]), axis=1)\n",
    "df[\"accuracy_comp\"] = df.accuracy.apply(lambda acc: 1 - acc)\n",
    "df[\"auc_comp\"] = df.auc.apply(lambda auc: 1 - auc)\n",
    "\n",
    "real_data_df[\"accuracy_comp\"] = real_data_df.accuracy.apply(lambda acc: 1 - acc)\n",
    "real_data_df[\"auc_comp\"] = real_data_df.auc.apply(lambda auc: 1 - auc)\n",
    "\n",
    "long_df = df.melt(\n",
    "        id_vars=[\"repeat_ind\", \"model\", \"model_short\", \"n_syn_datasets\", \"method\", \"dataset\", \"primal\", \"method_primal\"], \n",
    "        value_vars=[\"brier\", \"log_loss\", \"accuracy_comp\", \"auc_comp\"]\n",
    ")\n",
    "\n",
    "model_order_short = [\n",
    "    \"1-NN\", \"5-NN\", \"DT\", \"RF\", \"MLP\", \"GB\", \"SVM\", \"LogR\"\n",
    "]\n",
    "model_order = [\n",
    "    \"1-NN\", \"5-NN\", \"Decision Tree\", \"Random Forest\", \"MLP\", \"Gradient Boosting\", \n",
    "    \"SVM\", \"Logistic Regression\"\n",
    "]\n",
    "metric_order = list(long_df.variable.unique())\n",
    "n_repeats = len(df.repeat_ind.unique())\n",
    "\n",
    "min_real_data_metrics = {}\n",
    "for metric in metrics:\n",
    "    metric_df = real_data_df[[\"model\", metric]].groupby([\"model\"]).mean()\n",
    "    min_real_data_metrics[metric] = metric_df[metric].iloc[metric_df[metric].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_method(df, metric, save=False, selected_primal=None):\n",
    "    if selected_primal is not None:\n",
    "        df = df[df.primal.apply(lambda val: val in selected_primal)]\n",
    "\n",
    "    g = sns.FacetGrid(df, col=\"method_primal\", height=2.5, aspect=1.5)\n",
    "    # g.figure.suptitle(dataset_names[dataset])\n",
    "    g.map_dataframe(sns.barplot, x=\"model_short\", y=metric, order=model_order_short, hue=\"n_syn_datasets\", palette=\"flare\", errwidth=1.5)\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.axhline(min_real_data_metrics[metric], color=\"black\")\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid()\n",
    "    g.set(ylim=(min_real_data_metrics[metric] * 0.9, None))\n",
    "    g.set_xlabels(\"\")\n",
    "    g.set_ylabels(metric_names[metric])\n",
    "    g.set_titles(\"{col_name}\", fontweight=\"bold\")\n",
    "    g.tick_params(\"x\", labelrotation=45)\n",
    "    g.add_legend(title=\"m\")\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-{}-by-method.pdf\".format(fig_dir, dataset, metric), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_metrics(long_df, save=False):\n",
    "    g = sns.FacetGrid(long_df, col=\"method_primal\", row=\"variable\", sharey=\"row\", aspect=1.2)\n",
    "    # g.figure.suptitle(dataset_names[dataset])\n",
    "    g.map_dataframe(sns.barplot, x=\"model_short\", y=\"value\", order=model_order_short, hue=\"n_syn_datasets\", palette=\"flare\", errwidth=1.9)\n",
    "    for row_i in range(g.axes.shape[0]):\n",
    "        for col_i in range(g.axes.shape[1]):\n",
    "            g.axes[row_i, col_i].axhline(min_real_data_metrics[metric_order[row_i]], color=\"black\")\n",
    "            g.axes[row_i, col_i].set_ylim((min_real_data_metrics[metric_order[row_i]] * 0.9, None))\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid()\n",
    "    g.set_xlabels(\"\")\n",
    "    for (metric, method), ax in g.axes_dict.items():\n",
    "        if metric == \"log_loss\":\n",
    "            ax.set_yscale(\"log\")\n",
    "    for i, ax in enumerate(g.axes[:, 0]):\n",
    "        ax.set_ylabel(metric_names[metric_order[i]])\n",
    "    g.set_titles(\"{col_name}\", fontweight=\"bold\")\n",
    "    g.tick_params(\"x\", labelrotation=45)\n",
    "    g.add_legend(title=\"m\")\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-all-metrics.pdf\".format(fig_dir, dataset), bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_method(df, \"brier\", save=True, selected_primal=[\"Prob. Avg.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_metrics(long_df, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = df.groupby([\"model\", \"method_primal\", \"n_syn_datasets\"])[\"brier\"].aggregate([\"mean\", \"std\"])\n",
    "table[\"formatted\"] = table.apply(lambda row: \"{:.2f} $\\pm$ {:.3f}\".format(row[\"mean\"], row[\"std\"]), axis=1)\n",
    "table = table.reset_index(\"n_syn_datasets\").pivot(columns=\"n_syn_datasets\", values=\"formatted\")\n",
    "table.index.rename([\"Downstream\", \"Generator\"], inplace=True)\n",
    "table.columns.rename(\"m\", inplace=True)\n",
    "table = table.reindex(model_order, level=\"Downstream\", axis=\"index\")\n",
    "table\n",
    "# table.style.to_latex(fig_dir + \"{}-brier-table.tex\".format(dataset), hrules=True, clines=\"skip-last;data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table = table.query(\"(Downstream in ['1-NN', '5-NN', 'Decision Tree', 'Random Forest', 'Gradient Boosting']) and (Generator in ['AIM - Prob. Avg.', 'NAPSU-MQ - Prob. Avg.'])\")\n",
    "reduced_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiple-syn-datasets-ml-CFH753D6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
