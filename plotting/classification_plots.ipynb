{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from einops import rearrange, pack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../results/classification-datasets/\"\n",
    "fig_dir = \"../figures/classification/\"\n",
    "datasets = [\n",
    "    \"german-credit\", \n",
    "    \"adult\", \n",
    "    \"breast-cancer\"\n",
    "]\n",
    "\n",
    "metric_names = {\n",
    "    \"brier\": \"Brier Score\",\n",
    "    \"log_loss\": \"Cross Entropy\",\n",
    "    # \"accuracy\": \"Accuracy\",\n",
    "    # \"auc\": \"AUC\",\n",
    "    \"accuracy_comp\": \"1 - Accuracy\",\n",
    "    \"auc_comp\": \"1 - AUC\",\n",
    "}\n",
    "model_names = {\n",
    "    \"Logistic Regression\": \"LogR\",\n",
    "    \"1-NN\": \"1-NN\",\n",
    "    \"5-NN\": \"5-NN\",\n",
    "    \"Decision Tree\": \"DT\",\n",
    "    \"Random Forest\": \"RF\",\n",
    "    \"Gradient Boosting\": \"GB\",\n",
    "    \"MLP\": \"MLP\",\n",
    "    \"SVM\": \"SVM\",\n",
    "}\n",
    "method_names = {\n",
    "    \"ddpm\": \"DDPM\",\n",
    "    \"synthpop-proper\": \"SP-P\",\n",
    "}\n",
    "metrics = metric_names.keys()\n",
    "\n",
    "dataset_names = {\n",
    "    \"adult\": \"Adult\",\n",
    "    \"breast-cancer\": \"Breast Cancer\",\n",
    "    \"german-credit\": \"German Credit\",\n",
    "}\n",
    "inv_dataset_names = {val: key for key, val in dataset_names.items()}\n",
    "dataset_order = list(dataset_names.values())\n",
    "\n",
    "dfs = {}\n",
    "real_data_dfs = {}\n",
    "for dataset in datasets:\n",
    "    dfs[dataset] = pd.read_csv(\"{}{}/results.csv\".format(result_dir, dataset), index_col=False)\n",
    "    dfs[dataset][\"model_short\"] = dfs[dataset].model.apply(lambda m: model_names[m])\n",
    "    dfs[dataset].method = dfs[dataset].method.apply(lambda m: method_names[m])\n",
    "    dfs[dataset][\"dataset\"] = dataset_names[dataset]\n",
    "    real_data_dfs[dataset] = pd.read_csv(\"{}{}/real-data-results.csv\".format(result_dir, dataset), index_col=False)\n",
    "    \n",
    "for df in dfs.values():\n",
    "    df.primal = df.primal.apply(lambda m: \"Prob. Avg.\" if m== \"Primal\" else \"Log Prob. Avg.\")\n",
    "    df[\"method_primal\"] = df.apply(lambda row: \"{} - {}\".format(row[\"method\"], row[\"primal\"]), axis=1)\n",
    "    df[\"accuracy_comp\"] = df.accuracy.apply(lambda acc: 1 - acc)\n",
    "    df[\"auc_comp\"] = df.auc.apply(lambda auc: 1 - auc)\n",
    "\n",
    "for df in real_data_dfs.values():\n",
    "    df[\"accuracy_comp\"] = df.accuracy.apply(lambda acc: 1 - acc)\n",
    "    df[\"auc_comp\"] = df.auc.apply(lambda auc: 1 - auc)\n",
    "\n",
    "df_all_datasets = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "long_dfs = {\n",
    "    name: df.melt(\n",
    "        id_vars=[\"repeat_ind\", \"model\", \"model_short\", \"n_syn_datasets\", \"method\", \"dataset\", \"primal\", \"method_primal\"], \n",
    "        value_vars=[\"brier\", \"log_loss\", \"accuracy_comp\", \"auc_comp\"]\n",
    "    )\n",
    "    for name, df in dfs.items()\n",
    "}\n",
    "\n",
    "# model_order_short = list(dfs[\"german-credit\"].model_short.unique())\n",
    "model_order_short = [\n",
    "    \"1-NN\", \"5-NN\", \"DT\", \"RF\", \"MLP\", \"GB\", \"SVM\", \"LogR\"\n",
    "]\n",
    "model_order = [\n",
    "    \"1-NN\", \"5-NN\", \"Decision Tree\", \"Random Forest\", \"MLP\", \"Gradient Boosting\", \n",
    "    \"SVM\", \"Logistic Regression\"\n",
    "]\n",
    "# model_order = list(dfs[\"german-credit\"].model.unique())\n",
    "metric_order = list(long_dfs[\"german-credit\"].variable.unique())\n",
    "n_repeats = len(dfs[\"german-credit\"].repeat_ind.unique())\n",
    "\n",
    "real_data_metrics = {metric: {} for metric in metrics}\n",
    "min_real_data_metrics = {metric: {} for metric in metrics}\n",
    "for dataset in datasets:\n",
    "    for metric in metrics:\n",
    "        metric_df = real_data_dfs[dataset][[\"model\", metric]].groupby([\"model\"]).mean()\n",
    "        real_data_metrics[metric][dataset] = metric_df.reindex(model_order)\n",
    "        min_real_data_metrics[metric][dataset] = metric_df[metric].iloc[metric_df[metric].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    group_df = dfs[dataset].groupby([\"model\", \"method\", \"n_syn_datasets\", \"primal\"], as_index=False).mean(numeric_only=True)\n",
    "    for metric in metrics:\n",
    "        print(\"Lowest {} for {}\".format(metric_names[metric], dataset_names[dataset]))\n",
    "        print(group_df.iloc[group_df[metric].argmin()][[\"model\", \"method\", \"primal\", \"n_syn_datasets\", \"brier\", \"log_loss\", \"accuracy\", \"auc\"]])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_dfs = {}\n",
    "for dataset in datasets:\n",
    "    records = []\n",
    "    df = dfs[dataset]\n",
    "    for model in model_names.keys():\n",
    "        for method in method_names.values():\n",
    "            for primal in [\"Prob. Avg.\", \"Log Prob. Avg.\"]:\n",
    "                for repeat_ind in range(n_repeats):\n",
    "                    sdf = df[df.model == model]\n",
    "                    sdf = sdf[sdf.method == method]\n",
    "                    sdf = sdf[sdf.repeat_ind == repeat_ind]\n",
    "                    sdf = sdf[sdf.primal == primal]\n",
    "\n",
    "                    mse_series_m1 = sdf[sdf.n_syn_datasets == 1][\"brier\"]\n",
    "                    mse_series_m2 = sdf[sdf.n_syn_datasets == 2][\"brier\"]\n",
    "                    mse_1 = mse_series_m1.iloc[0] if len(mse_series_m1) > 0 else np.nan\n",
    "                    mse_2 = mse_series_m2.iloc[0] if len(mse_series_m2) > 0 else np.nan\n",
    "                    records.append({\n",
    "                        \"model\": model,\n",
    "                        \"method\": method,\n",
    "                        \"primal\": primal,\n",
    "                        \"repeat_ind\": repeat_ind,\n",
    "                        \"mse_1\": mse_1,\n",
    "                        \"red_estimate\": 2 * (mse_1 - mse_2)\n",
    "                    })\n",
    "    estimation_dfs[dataset] = pd.DataFrame.from_records(records)\n",
    "\n",
    "def estimate_mse(row, dataset):\n",
    "    estimation_df = estimation_dfs[dataset]\n",
    "    sel_estimate = estimation_df[\n",
    "        (estimation_df.model == row.model)\n",
    "        & (estimation_df.method == row.method)\n",
    "        & (estimation_df.primal == row.primal)\n",
    "        & (estimation_df.repeat_ind == row.repeat_ind)\n",
    "    ]\n",
    "    mse1 = sel_estimate.mse_1.iloc[0]\n",
    "    red_estimate = sel_estimate.red_estimate.iloc[0]\n",
    "    estimated_mse = mse1 - (1 - 1 / row.n_syn_datasets) * red_estimate\n",
    "    return estimated_mse\n",
    "\n",
    "for dataset in datasets:\n",
    "    dfs[dataset] = dfs[dataset].assign(est_mse=dfs[dataset].apply(lambda row: estimate_mse(row, dataset), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_model(df, dataset, metric, save=False):\n",
    "    g = sns.FacetGrid(df, col=\"model_short\", col_order=model_order_short, col_wrap=5)\n",
    "    g.figure.suptitle(dataset_names[dataset])\n",
    "    g.map_dataframe(sns.barplot, x=\"method_primal\", y=metric, hue=\"n_syn_datasets\")\n",
    "    for i, metric_val in enumerate(real_data_metrics[metric][dataset][metric]):\n",
    "        g.axes[i].axhline(metric_val, linestyle=\"dashed\", color=\"grey\")\n",
    "        g.axes[i].axhline(min_real_data_metrics[metric][dataset], color=\"black\")\n",
    "    for ax in g.axes:\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid()\n",
    "    g.set_xlabels(\"\")\n",
    "    g.set_ylabels(metric_names[metric])\n",
    "    g.tick_params(\"x\", labelrotation=90)\n",
    "    g.add_legend()\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-{}-by-model.pdf\".format(fig_dir, dataset, metric), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_by_method(df, dataset, metric, save=False, selected_primal=None, selected_method=None):\n",
    "    if selected_primal is not None:\n",
    "        df = df[df.primal.apply(lambda val: val in selected_primal)]\n",
    "    if selected_method is not None:\n",
    "        df = df[df.method.apply(lambda val: val in selected_method)]\n",
    "\n",
    "    g = sns.FacetGrid(df, col=\"method_primal\", height=2.2, aspect=1.2)\n",
    "    # g.figure.suptitle(dataset_names[dataset])\n",
    "    g.map_dataframe(sns.barplot, x=\"model_short\", y=metric, order=model_order_short, hue=\"n_syn_datasets\", palette=\"flare\", errwidth=0.7)\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.axhline(min_real_data_metrics[metric][dataset], color=\"black\")\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid()\n",
    "    g.set(ylim=(min_real_data_metrics[metric][dataset] * 0.9, None))\n",
    "    g.set_xlabels(\"\")\n",
    "    g.set_ylabels(metric_names[metric])\n",
    "    g.set_titles(\"{col_name}\", fontweight=\"bold\")\n",
    "    g.tick_params(\"x\", labelrotation=45)\n",
    "    g.add_legend(title=\"m\")\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-{}-by-method.pdf\".format(fig_dir, dataset, metric), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_by_dataset(df, selected_method, selected_primal, metric, save=False, file_suffix=\"\"):\n",
    "    df = df[df.method.apply(lambda val: val in selected_method)]\n",
    "    df = df[df.primal.apply(lambda val: val in selected_primal)]\n",
    "\n",
    "    g = sns.FacetGrid(df, col=\"dataset\", height=2.2, aspect=1.2, sharey=False, col_order=dataset_order)\n",
    "    g.map_dataframe(sns.barplot, x=\"model_short\", y=metric, order=model_order_short, hue=\"n_syn_datasets\", palette=\"flare\", errwidth=1.2)\n",
    "\n",
    "    for dataset, ax in g.axes_dict.items():\n",
    "        dataset_key = inv_dataset_names[dataset]\n",
    "        ax.axhline(min_real_data_metrics[metric][dataset_key], color=\"black\")\n",
    "        ax.set_ylim((min_real_data_metrics[metric][dataset_key] * 0.9, None))\n",
    "\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid()\n",
    "\n",
    "    g.tick_params(\"x\", labelrotation=45)\n",
    "    g.set_ylabels(metric_names[metric])\n",
    "    g.set_xlabels(\"\")\n",
    "    g.add_legend(title=\"m\")\n",
    "    g.set_titles(\"{col_name}\", fontweight=\"bold\")\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-by-dataset{}.pdf\".format(fig_dir, metric, file_suffix), bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_metrics(long_df, dataset, save=False):\n",
    "    g = sns.FacetGrid(long_df, col=\"method_primal\", row=\"variable\", sharey=\"row\", aspect=1.2)\n",
    "    # g.figure.suptitle(dataset_names[dataset])\n",
    "    g.map_dataframe(sns.barplot, x=\"model_short\", y=\"value\", order=model_order_short, hue=\"n_syn_datasets\", palette=\"flare\", errwidth=1.9)\n",
    "    for row_i in range(g.axes.shape[0]):\n",
    "        for col_i in range(g.axes.shape[1]):\n",
    "            g.axes[row_i, col_i].axhline(min_real_data_metrics[metric_order[row_i]][dataset], color=\"black\")\n",
    "            g.axes[row_i, col_i].set_ylim((min_real_data_metrics[metric_order[row_i]][dataset] * 0.9, None))\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid()\n",
    "    g.set_xlabels(\"\")\n",
    "    for (metric, method), ax in g.axes_dict.items():\n",
    "        if metric == \"log_loss\":\n",
    "            ax.set_yscale(\"log\")\n",
    "    for i, ax in enumerate(g.axes[:, 0]):\n",
    "        ax.set_ylabel(metric_names[metric_order[i]])\n",
    "    g.set_titles(\"{col_name}\", fontweight=\"bold\")\n",
    "    g.tick_params(\"x\", labelrotation=45)\n",
    "    g.add_legend(title=\"m\")\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-all-metrics.pdf\".format(fig_dir, dataset), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_mse_est(df, dataset, plot_order=model_order, save=False, file_suffix=\"\"):\n",
    "    df = df[df.primal == \"Prob. Avg.\"]\n",
    "    num_cols = 4 if len(plot_order) > 5 else len(plot_order)\n",
    "    g = sns.FacetGrid(df, col=\"model\", col_wrap=num_cols, col_order=plot_order, height=2.2, aspect=1.4)\n",
    "    # g.figure.suptitle(dataset_names[dataset])\n",
    "\n",
    "    g.map_dataframe(\n",
    "        sns.lineplot, x=\"n_syn_datasets\", y=\"brier\", hue=\"method\", style=\"method\",\n",
    "        markers=True,\n",
    "    )\n",
    "    legend_data = {\"{} Measured\".format(name): line for name, line in g._legend_data.items()}\n",
    "\n",
    "    g.map_dataframe(\n",
    "        sns.lineplot, x=\"n_syn_datasets\", y=\"est_mse\", hue=\"method\", style=\"method\",\n",
    "        linestyle=\"dashed\", palette=[\"C2\", \"C3\"], err_style=\"band\",\n",
    "        markers=[\"^\", \"v\"]\n",
    "    )\n",
    "    legend_data.update({\"{} Predicted\".format(name): line for name, line in g._legend_data.items()})\n",
    "    legend_data[\"DDPM Predicted\"].set_linestyle(\"dashed\")\n",
    "    legend_data[\"SP-P Predicted\"].set_linestyle(\"dashed\")\n",
    "\n",
    "    g.add_legend(legend_data, label_order=[\"DDPM Measured\", \"DDPM Predicted\", \"SP-P Measured\", \"SP-P Predicted\"], ncol=6, loc=\"upper right\", bbox_to_anchor=(0.52, 0))\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.grid()\n",
    "\n",
    "    g.set_ylabels(\"Brier Score\")\n",
    "    g.set_xlabels(\"m (# Synthetic Datasets)\")\n",
    "    g.set_titles(\"{col_name}\", fontweight=\"bold\")\n",
    "    if save:\n",
    "        plt.savefig(\"{}{}-mse-est{}.pdf\".format(fig_dir, dataset, file_suffix), bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german-credit\"\n",
    "plot_mse_est(dfs[dataset], dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse_est(dfs[\"german-credit\"], \"german-credit\", plot_order=[\"5-NN\", \"Decision Tree\", \"Gradient Boosting\", \"MLP\"], save=True, file_suffix=\"-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german-credit\"\n",
    "plot_all_metrics(long_dfs[dataset], dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german-credit\"\n",
    "plot_by_model(dfs[dataset], dataset, \"brier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german-credit\"\n",
    "plot_by_method(dfs[dataset], dataset, \"brier\", selected_primal=[\"Prob. Avg.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_dataset(df_all_datasets, [\"SP-P\"], [\"Prob. Avg.\"], \"brier\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    plot_by_method(dfs[dataset], dataset, \"brier\", save=True, selected_primal=[\"Prob. Avg.\"], selected_method=[\"SP-P\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    plot_all_metrics(long_dfs[dataset], dataset, save=True)\n",
    "    plot_mse_est(dfs[dataset], dataset, save=True)\n",
    "    # for metric in metrics:\n",
    "    #     plot_by_model(dfs[dataset], dataset, metric, save=False)\n",
    "    #     plot_by_method(dfs[dataset], dataset, metric, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, df in dfs.items():\n",
    "    table = df.groupby([\"model\", \"method_primal\", \"n_syn_datasets\"])[\"brier\"].aggregate([\"mean\", \"std\"])\n",
    "    table[\"formatted\"] = table.apply(lambda row: \"{:.2f} $\\pm$ {:.3f}\".format(row[\"mean\"], row[\"std\"]), axis=1)\n",
    "    table = table.reset_index(\"n_syn_datasets\").pivot(columns=\"n_syn_datasets\", values=\"formatted\")\n",
    "    table.index.rename([\"Downstream\", \"Generator\"], inplace=True)\n",
    "    table.columns.rename(\"m\", inplace=True)\n",
    "    table = table.reindex(model_order, level=\"Downstream\", axis=\"index\")\n",
    "    table.style.to_latex(fig_dir + \"{}-brier-table.tex\".format(dataset), hrules=True, clines=\"skip-last;data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_measured_col_name = \"Predicted / Measured\"\n",
    "for dataset, df in dfs.items():\n",
    "    df = df.melt(id_vars=[\"repeat_ind\", \"model\", \"n_syn_datasets\", \"method\"], value_vars=[\"brier\", \"est_mse\"], var_name=pred_measured_col_name)\n",
    "    table = df.groupby([\"model\", \"n_syn_datasets\", \"method\", pred_measured_col_name])[\"value\"].aggregate([\"mean\", \"std\"])\n",
    "    table[\"formatted\"] = table.apply(lambda row: \"{:.2f} $\\pm$ {:.3f}\".format(row[\"mean\"], row[\"std\"]), axis=1)\n",
    "    table = table.reset_index(\"n_syn_datasets\").pivot(columns=\"n_syn_datasets\", values=\"formatted\")\n",
    "    table.index.rename([\"Downstream\", \"Generator\", pred_measured_col_name], inplace=True)\n",
    "    table.columns.rename(\"m\", inplace=True)\n",
    "    table = table.reindex(model_order, level=\"Downstream\", axis=\"index\")\n",
    "    table.rename(index={\"est_mse\": \"Predicted\", \"brier\": \"Measured\"}, inplace=True)\n",
    "    table.style.to_latex(fig_dir + \"{}-mse-est-table.tex\".format(dataset), hrules=True, clines=\"skip-last;data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[\"german-credit\"]\n",
    "df = df[df.primal == \"Prob. Avg.\"]\n",
    "df = df.melt(id_vars=[\"repeat_ind\", \"model\", \"n_syn_datasets\", \"method\"], value_vars=[\"brier\", \"est_mse\"], var_name=pred_measured_col_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiple-syn-datasets-ml-CFH753D6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
